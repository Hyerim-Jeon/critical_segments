{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "207d3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48326a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_merge(file1_path, file2_path, output_path):\n",
    "    # 첫 번째 파일 읽기\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "\n",
    "    # 두 번째 파일 읽기\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "\n",
    "    # 결과를 저장할 데이터프레임 생성\n",
    "    result_rows = []\n",
    "\n",
    "    # 첫 번째 파일의 각 행을 순회하며 measure 범위와 feature를 추출\n",
    "    for _, row in df1.iterrows():\n",
    "        name = row['name']\n",
    "        feature = row['important_feature']\n",
    "        start = row['interval_start']\n",
    "        end = row['interval_end']\n",
    "\n",
    "        for measure in range(start, end + 1):\n",
    "            # 두 번째 파일에서 일치하는 measure와 feature 필터링\n",
    "            match_df = df2[(df2['measure'] == measure) & (df2['feature'] == feature)]\n",
    "\n",
    "            if not match_df.empty:\n",
    "                # 일치하는 데이터가 있는 경우\n",
    "                for _, match_row in match_df.iterrows():\n",
    "                    result_rows.append([\n",
    "                        match_row['measure'],\n",
    "                        match_row['feature'],\n",
    "                        match_row['feature_value']\n",
    "                    ])\n",
    "            else:\n",
    "                # 일치하는 데이터가 없는 경우\n",
    "                result_rows.append([measure, feature, 'null'])\n",
    "\n",
    "    # 결과 데이터프레임으로 변환\n",
    "    result_df = pd.DataFrame(result_rows, columns=['measure', 'feature', 'feature_value'])\n",
    "    \n",
    "    # critical_score 계산\n",
    "    critical_score_df = result_df.groupby(['measure', 'feature', 'feature_value']).size().reset_index(name='critical_score')\n",
    "\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    critical_score_df.to_csv(output_path, index=False)\n",
    "    print(f'Result saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87baf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(file1_path, file2_path, output_path):\n",
    "    # 두 CSV 파일 읽기\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "    \n",
    "    # 두 번째 파일에서 critical_score가 2 이상인 행만 필터링\n",
    "    #df2_filtered = df2[df2['critical_score'] >= 2]\n",
    "    \n",
    "    # concat 후 groupby로 처리\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # groupby 처리\n",
    "    def resolve_group(group):\n",
    "        result = group.iloc[0].copy()\n",
    "        \n",
    "        # feature_value: null이 아닌 값 선택\n",
    "        feature_values = group['feature_value'].dropna()\n",
    "        result['feature_value'] = feature_values.iloc[0] if not feature_values.empty else None\n",
    "\n",
    "        # critical_score: 합산\n",
    "        result['critical_score'] = group['critical_score'].fillna(0).sum()\n",
    "\n",
    "        return result\n",
    "\n",
    "    merged_df = combined_df.groupby(['measure', 'feature'], as_index=False).apply(resolve_group)\n",
    "\n",
    "    # 인덱스 초기화 (groupby 후 생성되는 계층 인덱스 제거)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 결과 저장\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f'Result saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c18830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pid_convert(pid_csv, performance_csv, output_csv):\n",
    "    # 파일 읽기\n",
    "    pid_df = pd.read_csv(pid_csv)\n",
    "    performance_df = pd.read_csv(performance_csv)\n",
    "    \n",
    "    # midi_path와 pid를 딕셔너리로 매핑\n",
    "    path_to_pid = dict(zip(pid_df['midi_path'], pid_df['pid']))\n",
    "    \n",
    "    # performance_id를 pid로 변환\n",
    "    performance_df['pid'] = performance_df['performance_id'].map(path_to_pid)\n",
    "    \n",
    "    # 변환 과정: measure, feature, feature_value로 변경\n",
    "    performance_df['measure'] = performance_df['bar'] + 1\n",
    "    performance_df['feature'] = performance_df['feature_idx'] + 1\n",
    "    performance_df['feature_value'] = performance_df['value']\n",
    "    \n",
    "    # 필요한 열 선택 및 순서 지정\n",
    "    result_df = performance_df[['pid', 'measure', 'feature', 'feature_value']]\n",
    "\n",
    "    \n",
    "    ###chopin - pid가 45에서 60 사이인 행만 필터링\n",
    "    filtered_df = result_df[(result_df['pid'] >= 45) & (result_df['pid'] <= 60)]\n",
    "    ###beethoven - pid가 45미만, 60 초과인 행만 필터링\n",
    "    #filtered_df = result_df[(result_df['pid'] < 45) | (result_df['pid'] > 60)]\n",
    "    \n",
    "    filtered_df = filtered_df.drop_duplicates(subset=['pid', 'measure', 'feature'])\n",
    "    \n",
    "    # 결과 CSV 파일 저장\n",
    "    filtered_df.to_csv(output_csv, index=False)\n",
    "    print(f'변환된 데이터가 {output_csv}로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8e16a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(performance_csv, guideline_csv, output_csv):\n",
    "    # CSV 파일 읽기\n",
    "    performance_df = pd.read_csv(performance_csv)\n",
    "    guideline_df = pd.read_csv(guideline_csv)\n",
    "    \n",
    "    \n",
    "    \n",
    "    performance_df['measure'] = performance_df['measure'].astype(float)\n",
    "    performance_df['feature'] = performance_df['feature'].astype(float)\n",
    "    guideline_df['measure'] = guideline_df['measure'].astype(float)\n",
    "    guideline_df['feature'] = guideline_df['feature'].astype(float)\n",
    "    \n",
    "\n",
    "    # measure와 feature를 기준으로 병합 (right join)\n",
    "    merged_df = pd.merge(performance_df, guideline_df, on=['measure', 'feature'], how='right')\n",
    "\n",
    "\n",
    "    # difference 계산\n",
    "    merged_df['difference'] = merged_df['feature_value_x'] - merged_df['feature_value_y']\n",
    "    \n",
    "    # 열 이름 변경\n",
    "    merged_df = merged_df.rename(columns={'feature_value_x': 'feature_value','feature_value_y': 'guideline_value', 'critical_score': 'critical_score'})\n",
    "    \n",
    "    # 필요한 열만 선택\n",
    "    result_df = merged_df[['pid', 'measure', 'feature', 'feature_value', 'guideline_value', 'difference', 'critical_score']]\n",
    "    \n",
    "    ### chopin\n",
    "    result_df = result_df[result_df['measure'] < 80]\n",
    "    ### beethoven\n",
    "    #result_df = result_df[result_df['measure'] < 306]\n",
    "    \n",
    "    # 결과 저장\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    print(f'비교 결과가 {output_csv}로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "630c8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(item):\n",
    "    \n",
    "    feature_mapping = {\n",
    "        'feature': [1, 9, 11, 2, 3, 7, 6, 8, 10, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "        'new_feature': [11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 10, 16, 17, 32],\n",
    "        'back': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        'lv1': [1,2,2,3,3,4,5,5,5,6,6,7,7,7,7,8,8,8,9,1,4,4,9],\n",
    "    }\n",
    "\n",
    "    df2 = pd.DataFrame(feature_mapping)\n",
    "    subset = df2[df2['new_feature'] == item]\n",
    "\n",
    "    feature_value = subset.iloc[0]['feature']\n",
    "    back_value = subset.iloc[0]['back']\n",
    "    return int(feature_value), int(back_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffbc91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lv1(item):\n",
    "    \n",
    "    feature_mapping = {\n",
    "        'feature': [1, 9, 11, 2, 3, 7, 6, 8, 10, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "        'new_feature': [11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 10, 16, 17, 32],\n",
    "        'back': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        'lv1': [1,2,2,3,3,4,5,5,5,6,6,7,7,7,7,8,8,8,9,1,4,4,9],\n",
    "    }\n",
    "\n",
    "    df2 = pd.DataFrame(feature_mapping)\n",
    "    subset = df2[df2['new_feature'] == item]\n",
    "\n",
    "    feature_value = subset.iloc[0]['lv1']\n",
    "    return int(feature_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c15fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(annotation, expid, output_csv):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(annotation)  # 병합된 테이블\n",
    "    df = df[df['pid'] != expid] # expid에 해당하는 pid 제외\n",
    "\n",
    "    # 결과 저장을 위한 리스트\n",
    "    results = []\n",
    "\n",
    "    # 전체 measure 범위를 가져옴\n",
    "    min_measure = df['start_measure'].min()\n",
    "    max_measure = df['end_measure'].max()\n",
    "\n",
    "    # measure 단위로 반복\n",
    "    for measure in range(min_measure, max_measure + 1):\n",
    "        df_measure = df[(df['start_measure'] <= measure) & (df['end_measure'] >= measure)]\n",
    "        df_measure = df_measure.drop_duplicates()\n",
    "        # Feature별 저장을 위한 딕셔너리\n",
    "        feature_results = {}\n",
    "\n",
    "        # 모든 pid (annotation) 반복\n",
    "        for _, row in df_measure.iterrows():\n",
    "            level = row['level']\n",
    "            item = row['item']\n",
    "            pid = row['pid']  # 현재 row의 pid 저장\n",
    "\n",
    "            # Level 2만 처리\n",
    "            if level != 2:\n",
    "                continue\n",
    "\n",
    "            suggestion_value = row['suggestion']\n",
    "            observation_value = row['observation']\n",
    "\n",
    "            # Feature Mapping 조회\n",
    "            feature, back = get_feature(item)\n",
    "            if feature is None:\n",
    "                continue  # 매핑되지 않은 feature는 스킵\n",
    "\n",
    "            if feature not in feature_results:\n",
    "                feature_results[feature] = {\"critical_score\": 0, \"feature_sum\": 0}\n",
    "\n",
    "            # Back 처리\n",
    "            if back == 1:\n",
    "                if suggestion_value > 0 : \n",
    "                    suggestion_value = 8 - suggestion_value\n",
    "                if observation_value > 0 : \n",
    "                    observation_value = 8 - observation_value\n",
    "\n",
    "            lv1 = get_lv1(item)\n",
    "\n",
    "            # Suggestion 값이 있으면 바로 반영\n",
    "            if suggestion_value > 0:\n",
    "                \n",
    "                # -1 ~ 1 정규화\n",
    "                suggestion_value = (suggestion_value - 4) / 3.0\n",
    "\n",
    "                feature_results[feature][\"critical_score\"] += 1\n",
    "                feature_results[feature][\"feature_sum\"] += suggestion_value\n",
    "\n",
    "            # Observation 값이 있으면 처리\n",
    "            elif observation_value > 0:\n",
    "                \n",
    "                # -1 ~ 1 정규화\n",
    "                observation_value = (observation_value - 4) / 3.0\n",
    "                \n",
    "                feature_results[feature][\"critical_score\"] += 1\n",
    "\n",
    "                # Level 1 값 찾기 (같은 pid를 가진 것 중에서 찾기)\n",
    "                level1_rows = df_measure[(df_measure['level'] == 1) & (df_measure['pid'] == pid)]\n",
    "                matched_lv1 = level1_rows[level1_rows['item'] == lv1]\n",
    "\n",
    "                if not matched_lv1.empty:\n",
    "                    # Level 1의 observation 값을 사용\n",
    "                    level1_value = matched_lv1.iloc[0]['observation']\n",
    "                    feature_results[feature][\"feature_sum\"] += observation_value * ((level1_value / 5) - 1)\n",
    "                else:\n",
    "                    # Level 0 값 (같은 row의 score 값)\n",
    "                    level0_value = row['score']\n",
    "                    if level0_value is None:\n",
    "                        level0_value = abs(observation_value - 4) * 10 / 3\n",
    "                    feature_results[feature][\"feature_sum\"] += observation_value * ((level0_value / 5) - 1)\n",
    "\n",
    "        # Feature별 Feature Value 계산 및 저장\n",
    "        for feature, values in feature_results.items():\n",
    "            feature_value = values[\"feature_sum\"] / values[\"critical_score\"] if values[\"critical_score\"] > 0 else 0\n",
    "            results.append({\n",
    "                'measure': measure,\n",
    "                'feature': feature,\n",
    "                'critical_score': values[\"critical_score\"],\n",
    "                'feature_value': feature_value\n",
    "            })\n",
    "\n",
    "    # 결과를 데이터프레임으로 변환\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results[df_results['feature'] < 20] # feature 19까지만 남기기\n",
    "\n",
    "    # CSV 저장\n",
    "    df_results.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41c46fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(annotation, output_csv):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(annotation)  # 병합된 테이블\n",
    "\n",
    "    # 결과 저장을 위한 리스트\n",
    "    results = []\n",
    "\n",
    "    # 전체 measure 범위를 가져옴\n",
    "    min_measure = df['start_measure'].min()\n",
    "    max_measure = df['end_measure'].max()\n",
    "\n",
    "    # measure 단위로 반복\n",
    "    for measure in range(min_measure, max_measure + 1):\n",
    "        df_measure = df[(df['start_measure'] <= measure) & (df['end_measure'] >= measure)]\n",
    "        df_measure = df_measure.drop_duplicates()\n",
    "\n",
    "        for _, row in df_measure.iterrows():\n",
    "            level = row['level']\n",
    "            item = row['item']\n",
    "            pid = row['pid']\n",
    "            suggestion_value = row['suggestion']\n",
    "            observation_value = row['observation']\n",
    "\n",
    "            # Level 2만 처리\n",
    "            if level != 2:\n",
    "                continue\n",
    "\n",
    "            # Feature 매핑\n",
    "            feature, back = get_feature(item)\n",
    "            if feature is None:\n",
    "                continue\n",
    "\n",
    "            # Back 처리\n",
    "            if back == 1:\n",
    "                if suggestion_value > 0:\n",
    "                    suggestion_value = 8 - suggestion_value\n",
    "                if observation_value > 0:\n",
    "                    observation_value = 8 - observation_value\n",
    "\n",
    "            # 정규화\n",
    "            if suggestion_value > 0:\n",
    "                suggestion_norm = (suggestion_value - 4) / 3.0\n",
    "            else:\n",
    "                suggestion_norm = None\n",
    "\n",
    "            if observation_value > 0:\n",
    "                observation_norm = (observation_value - 4) / 3.0\n",
    "            else:\n",
    "                observation_norm = None\n",
    "\n",
    "            results.append({\n",
    "                'pid': pid,\n",
    "                'measure': measure,\n",
    "                'feature': feature,\n",
    "                'suggestion': suggestion_norm,\n",
    "                'observation': observation_norm\n",
    "            })\n",
    "\n",
    "    # 결과 저장\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results[df_results['feature'] < 19]  # feature 18까지만 유지\n",
    "    df_results.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecd35982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard2(annotation, output_csv):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(annotation)\n",
    "\n",
    "    # 결과를 저장할 리스트\n",
    "    results = []\n",
    "\n",
    "    # 각 row의 measure 범위를 풀어서 저장\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        start = int(row['start_measure'])\n",
    "        end = int(row['end_measure'])\n",
    "\n",
    "        for measure in range(start, end + 1):\n",
    "            results.append({'pid': pid, 'measure': measure})\n",
    "\n",
    "    # DataFrame 생성 및 중복 제거\n",
    "    df_result = pd.DataFrame(results).drop_duplicates().sort_values(['pid', 'measure'])\n",
    "\n",
    "    # 저장\n",
    "    df_result.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1600f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pid_drop(performance, expid, output_csv):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(performance)  # 병합된 테이블\n",
    "    df = df[df['pid'] == expid] # expid에 해당하는 pid만 남김\n",
    "    min_val = df['feature_value'].min()\n",
    "    max_val = df['feature_value'].max()\n",
    "\n",
    "    # [-1, 1]로 정규화\n",
    "    df['feature_value'] = 2 * (df['feature_value'] - min_val) / (max_val - min_val) - 1\n",
    "    df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84d593ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 데이터가 result/pid_v5.csv로 저장되었습니다.\n",
      "Result saved to result/58_inter3.csv\n",
      "Result saved to result/58_inter4.csv\n",
      "비교 결과가 result/58_diff.csv로 저장되었습니다.\n",
      "Result saved to result/60_inter3.csv\n",
      "Result saved to result/60_inter4.csv\n",
      "비교 결과가 result/60_diff.csv로 저장되었습니다.\n",
      "Result saved to result/56_inter3.csv\n",
      "Result saved to result/56_inter4.csv\n",
      "비교 결과가 result/56_diff.csv로 저장되었습니다.\n",
      "Result saved to result/54_inter3.csv\n",
      "Result saved to result/54_inter4.csv\n",
      "비교 결과가 result/54_diff.csv로 저장되었습니다.\n",
      "Result saved to result/53_inter3.csv\n",
      "Result saved to result/53_inter4.csv\n",
      "비교 결과가 result/53_diff.csv로 저장되었습니다.\n",
      "Result saved to result/55_inter3.csv\n",
      "Result saved to result/55_inter4.csv\n",
      "비교 결과가 result/55_diff.csv로 저장되었습니다.\n",
      "Result saved to result/59_inter3.csv\n",
      "Result saved to result/59_inter4.csv\n",
      "비교 결과가 result/59_diff.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###embedding model training\n",
    "perf = 'concatenated_v5.csv'\n",
    "perf2 = 'result/pid_v5.csv'\n",
    "\n",
    "###chopin\n",
    "anno = 'merged_c.csv'\n",
    "crit = 'c_score.csv'\n",
    "\n",
    "###beethoven\n",
    "#anno = 'merged_b.csv'\n",
    "#crit = 'b_score.csv'\n",
    "\n",
    "### pid_convert에서 chopin/beethoven 곡에 해당하는 pid만 남기기\n",
    "pid_convert('pidname.csv', perf, perf2)\n",
    "\n",
    "perf_df = pd.read_csv(perf2)\n",
    "pids = perf_df['pid'].unique() # pid 열에 있는 고유값 목록 가져오기\n",
    "\n",
    "for expid in pids:\n",
    "    \n",
    "    # 각 expid에 대해 파이프라인 실행\n",
    "    inter1 = f'result/{expid}_inter1.csv'\n",
    "    inter2 = f'result/{expid}_inter2.csv'\n",
    "    inter3 = f'result/{expid}_inter3.csv'\n",
    "    inter4 = f'result/{expid}_inter4.csv'\n",
    "    diff = f'result/{expid}_diff.csv'\n",
    "\n",
    "    pid_drop(perf2, expid, inter1)\n",
    "    overlap(anno, expid, inter2)\n",
    "    preprocess_merge(crit, inter2, inter3)\n",
    "    merge(inter3, inter2, inter4)\n",
    "    ### chopin measure 79 beethoven measure 305\n",
    "    compare(inter1, inter4, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3a66d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%%%%%%etc%%%%%%%%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%%%%%%%etc%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65dc5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 데이터가 result/pid_v6.csv로 저장되었습니다.\n",
      "[71 84 76 80 20 61 67 66 77 62 72 65 64 83 81 69 79 75 85 70 78 73 63 74\n",
      " 82 68]\n"
     ]
    }
   ],
   "source": [
    "perf = 'concatenated_v6.csv'\n",
    "perf2 = 'result/pid_v6.csv'\n",
    "\n",
    "pid_convert('pidname.csv', perf, perf2)\n",
    "\n",
    "perf_df = pd.read_csv(perf2)\n",
    "pids = perf_df['pid'].unique() # pid 열에 있는 고유값 목록 가져오기\n",
    "print(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "106457bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 비교할 annotation 데이터 정리\n",
    "standard('merged_b.csv', 'standard_b.csv')\n",
    "standard2('merged_b.csv', 'standard2_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43f53b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 비교할 annotation 데이터 정리 > 구간만 잡아서 비교\n",
    "standard2(anno, 'standard2_c.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
